import io
import os.path

import streamlit as st
from PIL import Image

from transformers import BlipProcessor, BlipForConditionalGeneration
from translate import Translator


def load_image():
    """
    –§—É–Ω–∫—Ü–∏—è load_image() –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –≤—ã–≤–µ—Å—Ç–∏ –µ–≥–æ –Ω–∞ —ç–∫—Ä–∞–Ω
    """
    st.header("–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    uploaded_file = st.file_uploader(label="–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è")

    if uploaded_file is not None:
        image_data = uploaded_file.getvalue()
        st.image(image_data)
        image_data_open = Image.open(io.BytesIO(image_data))
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –±—É—Ñ—Ñ–µ—Ä–∞
        image_data_open.save(f"{os.path.dirname(__file__)}/image_predict_tmp.png")
        return image_data_open
    else:
        return None


@st.cache_resource
def load_models():
    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
    model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-large")
    return processor, model


def get_description_image():
    """
    –§—É–Ω–∫—Ü–∏—è get_description_image() –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –µ–≥–æ
    """
    processor, model = load_models()

    raw_image = Image.open(f"{os.path.dirname(__file__)}/image_predict_tmp.png")

    text = "a photography of"
    inputs = processor(raw_image, text, return_tensors="pt")

    out = model.generate(**inputs)
    out2 = processor.decode(out[0], skip_special_tokens=True)

    translator = Translator(from_lang="en", to_lang="ru")
    text_rus = translator.translate(out2[0].upper() + out2[1:])
    return text_rus


# –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –ø—É—Ç–∏ –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –∏–∑ –±—É—Ñ—Ñ–µ—Ä–∞
file_path = f"{os.path.dirname(__file__)}/image_predict_tmp.png"
absolute_path = os.path.abspath(file_path)


def run_():
    """
    –§—É–Ω–∫—Ü–∏—è run_() –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–π–¥–µ–Ω–æ –ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º. –í —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ –ø—É—Ç—å –∫
    –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –Ω–∞–π–¥–µ–Ω, –∑–∞–ø—É—Å–∫–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é get_description_image() –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏—è.
    """
    try:
        if absolute_path:
            try:
                if st.button("–ü–æ–ª—É—á–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"):
                    st.text(get_description_image())
            except:
                st.warning("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ", icon="üöÄ")
        else:
            exit()
        if f"{os.path.dirname(__file__)}/image_predict_tmp.png" in absolute_path:
            os.remove(f"{os.path.dirname(__file__)}/image_predict_tmp.png")
    except FileNotFoundError:
        return "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ"
